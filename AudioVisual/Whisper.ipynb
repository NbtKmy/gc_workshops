{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NbtKmy/gc_workshops/blob/main/Whisper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V9c78y55iwze"
      },
      "source": [
        "# OpenAI-Whisper\n",
        "Whisper ist ein Spracherkennungsmodel, das von OpenAI entwickelt worden ist.\n",
        "Mit Whisper kann man zum Beispiel eine gesprochene Sprache (Audio-Datei) in einen Text umwandeln (transkribieren).\n",
        "\n",
        "Im [Github-Repository](https://github.com/openai/whisper) findet man die Code und Beschreibungen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEeO6YoM7aEW"
      },
      "source": [
        "## Vor der Installation\n",
        "Vor der Installation überprüfen wir zuerst, ob GPU (Graphicprozessor) für dieses Notebook freigeschaltet ist. Viele KI-Modelle, darunter auch Whisper, braucht GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDT62dUQkLff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6dae5664-3f3d-4264-e1a8-84e0e7ec9f5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Oct 17 12:17:59 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OC3BCeplPQO"
      },
      "source": [
        "Wenn der Befehl oben fehlgeschlagen ist, dann muss man die Einstellung ändern.\n",
        "\"Bearbeiten\"-\"Notebook Einstellungen\" klicken. Dann im geöffneten Popup bei \"Hardwarebeschleuniger\" \"GPU\" anwählen und Speichern.\n",
        "\n",
        "Google bietet schnelle Prozessor wie GPU an, aber nur bis zur gewissen Rechnungskapazität und bis zum gewissen Laufzeit des Prozessors. Wenn man noch mehr Rechnungskapazität will, kann man entweder die Angebote von unterschiedlichen Anbietern beziehen oder Graphic Board selber anschaffen und in dem eigenen PC einbauen.\n",
        "\n",
        "Die [**Science IT**](https://www.zi.uzh.ch/en/teaching-and-research/science-it/computing.html) an der Universität Zürich bietet ebenso die Dienstleistung für solche GPU an."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5dOVCYQkE49"
      },
      "source": [
        "## Installieren\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Libraries cohere und openai sind notwendig für whisper (Stand: 18.10.2023)\n",
        "!pip install cohere openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HFb13ZIrTen",
        "outputId": "0c4672fc-d28e-42ee-ef56-6061f8c44b6d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-4.30-py3-none-any.whl (47 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.8.6)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro==1.8.2 (from cohere)\n",
            "  Downloading fastavro-1.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.8.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2023.7.22)\n",
            "Installing collected packages: fastavro, backoff, openai, cohere\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 cohere-4.30 fastavro-1.8.2 openai-0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Jd4NlqtIoN-K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c34fe805-500e-414d-fba6-7f3e1ff4d21b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-n2yx0moa\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-n2yx0moa\n",
            "  Resolved https://github.com/openai/whisper.git to commit b38a1f20f4b23f3f3099af2c3e0ca95627276ddf\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230918) (10.1.0)\n",
            "Collecting tiktoken==0.3.3 (from openai-whisper==20230918)\n",
            "  Downloading tiktoken-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230918) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230918) (2.31.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230918) (3.27.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230918) (3.12.4)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230918) (17.0.2)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230918) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230918) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230918) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230918) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230918) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230918) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230918) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20230918) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20230918) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230918-py3-none-any.whl size=798405 sha256=0e55d806e5f41fe5e6b48ef6b15bdfe446a105721005f1febfbfec2657744556\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mk_05sh8/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "Successfully installed openai-whisper-20230918 tiktoken-0.3.3\n"
          ]
        }
      ],
      "source": [
        "# Wenn man Whisper von Github installieren will\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "\n",
        "# Sonst über pip kann man auch whisper installieren\n",
        "#!pip install -U openai-whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4k4WMCBoTuD"
      },
      "source": [
        "Dann ffmpeg installieren"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "hR99Foh9oa-k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "261b93b7-f0ef-4436-fef4-94a9d2e03a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\u001b[33m\r0% [Connecting to archive.ubuntu.com (185.125.190.36)] [1 InRelease 14.2 kB/110\u001b[0m\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,005 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease [18.1 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,082 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,349 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,270 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:15 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main Sources [2,229 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy/main amd64 Packages [1,144 kB]\n",
            "Fetched 8,439 kB in 5s (1,807 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "28 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 28 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0V_e6Lbo22K"
      },
      "source": [
        "## Einfache Anwendung durch Commandline\n",
        "\n",
        "Zuerst ein Audio-File (.flac, .mp3 oder .wav) hochladen!\n",
        "\n",
        "\n",
        "\n",
        "Bei der Anwendung kann man unterschiedliche Modelle auswählen.\n",
        "\n",
        "Laut der [offziellen Angabe](https://github.com/openai/whisper#available-models-and-languages) gibt es 5 multi-linguale Modelle.\n",
        "\n",
        "Je nach der Sprache ergeben sich unterschiedliche Fehlerquoten."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_3jzBqdeXy1"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "uploaded_filename = list(uploaded.keys())[0]\n",
        "# Unter dem Variabel uploaded_filename ist der Pfad zu dem hochgeladenen File untergebracht"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ma5usGUIHOq2"
      },
      "outputs": [],
      "source": [
        "# Audio anhören\n",
        "from IPython.display import Audio\n",
        "Audio(uploaded_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbOwRcuWqZ1Q"
      },
      "outputs": [],
      "source": [
        "!whisper $uploaded_filename --model medium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j2dnVLDu22kQ"
      },
      "outputs": [],
      "source": [
        "!whisper $uploaded_filename --task translate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJGzAJ_B35YI"
      },
      "source": [
        "## In einer Python-Code verwenden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IL_btw3E3-JA"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "\n",
        "model = whisper.load_model('medium')\n",
        "model.device\n",
        "result = model.transcribe(uploaded_filename)\n",
        "print(result['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ujfNP_Dwk4u"
      },
      "source": [
        "Mit der Funktion \"transcribe()\" wird die Audio-Eingabe pro 30 sec. getrennt und Stück für Stück verarbeitet:\n",
        "\n",
        ">Internally, the transcribe() method reads the entire file and processes the audio with a sliding 30-second window, performing autoregressive sequence-to-sequence predictions on each window.\n",
        "(aus: [Python usage](https://github.com/openai/whisper#python-usage))\n",
        "\n",
        "Mit der Funktion \"transcribe()\" kann man deshalb eine Audio-Eingabe länger als 30 sec. am Stück verarbeiten.\n",
        "```\n",
        "model = whisper.load_model([model_size])\n",
        "audio = whisper.load_audio([filename])\n",
        "result = model.transcribe(audio, verbose=True, temperature=0.8, language=[lang])\n",
        "```\n",
        "\n",
        "Wenn man die andere Funktion \"decode()\" verwendet, muss die Länge der Audio-Eingabe max. 30 sec. sein. Wenn die Audio-Aufnahme länger als 30 sec. ist, braucht man ein wenig creativ zu sein. Siehe unten..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4N9nEIevstX"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "\n",
        "fileName = 'result_whisper'#@param {type:'string'}\n",
        "lang = 'de'#@param ['ja', 'en', 'de']\n",
        "model_size = 'medium'#@param ['tiny', 'base', 'small', 'medium', 'large']\n",
        "model = whisper.load_model(model_size)\n",
        "\n",
        "\n",
        "audio = whisper.load_audio(uploaded_filename)\n",
        "outputTextsArr = []\n",
        "\n",
        "while audio.size > 0:\n",
        "    tirmedAudio = whisper.pad_or_trim(audio)\n",
        "    startIdx = tirmedAudio.size\n",
        "    audio = audio[startIdx:]\n",
        "\n",
        "    mel = whisper.log_mel_spectrogram(tirmedAudio).to(model.device)\n",
        "\n",
        "    options = whisper.DecodingOptions(language=lang, without_timestamps=True)\n",
        "    result = whisper.decode(model, mel, options)\n",
        "    outputTextsArr.append(result.text)\n",
        "\n",
        "outputTexts = ' '.join(outputTextsArr)\n",
        "print(outputTexts)\n",
        "\n",
        "\n",
        "with open(f'{fileName}.txt', 'w') as f:\n",
        "    f.write(outputTexts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oytVhf9w6dY_"
      },
      "source": [
        "## Ein YouTube-Video mit Untertitel oder Übersetzung versehen\n",
        "\n",
        "Um ein YouTube-Video herunterzuladen, verwendet man hier [yt-dlp](https://pypi.org/project/yt-dlp/).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M23vFQk46msY"
      },
      "outputs": [],
      "source": [
        "!pip install -U yt-dlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Y1RuLCn7ZF_"
      },
      "outputs": [],
      "source": [
        "from yt_dlp import YoutubeDL\n",
        "\n",
        "yt_url = 'https://youtu.be/Ifkhj0XtGGM'#@param {type:'string'}\n",
        "vd_filename = 'test'#@param{type:'string'}\n",
        "vd_filename += '.mp4'\n",
        "\n",
        "ydl_opts = {'format': 'best',\n",
        "            'outtmpl': vd_filename }\n",
        "with YoutubeDL(ydl_opts) as ydl:\n",
        "    ydl.download([yt_url])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-mGx3QrA3jB"
      },
      "source": [
        "...Überprüfen, ob das Video tatsächlich heruntergeladen ist..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBu8CqykAOnD"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open(vd_filename, 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"100%\" height=\"100%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spHbeMejeSsC"
      },
      "outputs": [],
      "source": [
        "!pip install -U srt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4y_hImoOecYM"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "from datetime import timedelta\n",
        "from srt import Subtitle\n",
        "import srt\n",
        "\n",
        "\n",
        "\n",
        "# Text umbrechen, wenn eine Zeile lang ist　... wahrscheinlich braucht man nicht...\n",
        "def add_line(line):\n",
        "    new_line = line\n",
        "    space_count = new_line.count(' ')\n",
        "    list_line = list(new_line)\n",
        "    space_max = 4\n",
        "    if space_count > space_max :\n",
        "        space_index = [i for i, x in enumerate(list_line) if x == ' ']\n",
        "        new_line = line[:space_index[space_max]] + '\\n' + line[space_index[space_max]:]\n",
        "\n",
        "    return new_line\n",
        "\n",
        "# Übersetzung erstellen\n",
        "model = whisper.load_model('medium')\n",
        "result = model.transcribe(vd_filename, task='translate')\n",
        "\n",
        "segments = result['segments']\n",
        "\n",
        "subtitles = []\n",
        "\n",
        "for segment in segments:\n",
        "    index = segment['id'] + 1\n",
        "    start = segment['start']\n",
        "    end = segment['end']\n",
        "    text = add_line(segment['text'])\n",
        "    subtitle = Subtitle(\n",
        "                   index=index,\n",
        "                   start=timedelta(seconds=timedelta(seconds=start).seconds, microseconds=timedelta(seconds=start).microseconds),\n",
        "                   end=timedelta(seconds=timedelta(seconds=end).seconds, microseconds=timedelta(seconds=end).microseconds),\n",
        "                   content=text,\n",
        "                   proprietary=''\n",
        "              )\n",
        "    subtitles.append(subtitle)\n",
        "\n",
        "# Untertitel speichern\n",
        "with open('subtitle.srt', mode='w', encoding='utf-8') as f:\n",
        "    f.write(srt.compose(subtitles))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ffmpeg-python"
      ],
      "metadata": {
        "id": "DNtIzXnAtemw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ffmpeg\n",
        "\n",
        "# Das Video mit Untertitel versehen und speichern\n",
        "video = ffmpeg.input(vd_filename)\n",
        "audio = video.audio\n",
        "ffmpeg.concat(video.filter('subtitles', 'subtitle.srt'), audio, v=1, a=1).output('output_vid.mp4').run()"
      ],
      "metadata": {
        "id": "eaZV7kLv8QxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OcfWgXSH6csp"
      },
      "outputs": [],
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('output_vid.mp4', 'rb').read()\n",
        "vid_wSub = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"100%\" height=\"100%\" controls>\n",
        "      <source src=\"{vid_wSub}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOdeCpPOYJtmWI7Mf7eOgxA",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}