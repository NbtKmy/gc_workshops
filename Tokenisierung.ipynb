{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPxsPgLRbjfq+BgZwyq7J5K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NbtKmy/gc_workshops/blob/main/Tokenisierung.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NLP (Natural Language Processing)\n",
        "\n",
        "Zum Einstieg des NLP sollen wir Tokenisierung lernen.\n",
        "Tokenisierung ist ein wichtiger Schritt, damit ein Textkorpus maschnell bearbeitet werden kann.\n",
        "\n",
        "## Token? Tokenisierung?\n",
        "\n",
        "Die Definition findet man in der Companion Website für das Buch \"Manning, Raghavan und Schütze. Indriduction to Information Retrieval. Cambridge Univ. Press, 2008.\"\n",
        "\n",
        ">Given a character sequence and a defined document unit, tokenization is the task of chopping it up into pieces, called tokens , perhaps at the same time throwing away certain characters, such as punctuation. [...]\n",
        "These tokens are often loosely referred to as terms or words, but it is sometimes important to make a type/token distinction. A token is an instance of a sequence of characters in some particular document that are grouped together as a useful semantic unit for processing.\n",
        "\n",
        "(Aus: [companion website for the book \"Christopher D. Manning, Prabhakar Raghavan and Hinrich Schütze, Introduction to Information Retrieval, Cambridge University Press. 2008\"](https://nlp.stanford.edu/IR-book/))\n",
        "\n",
        "\n",
        "In dieser Einführung sehen wir Tokenisierung mit NLTK und spaCy an.\n",
        "Danach probieren wir kurz Tokenisierung mit tiktoken aus. Tiktoken ist Tokenizer von OpenAI. Dadurch sehen wir konkret den Unterschied zwischen \"lexical tokenization\" und \"probabilistic tokonization\".\n",
        "\n",
        "- [NLTK](https://www.nltk.org/)(Natural Language Tookkit) ist eine Plattform, die die Library für Python zum Zweck NLP erstellt und anbietet.\n",
        "- [spaCy](https://spacy.io/) ist ein open source Software Library für NLP. Anders als NLTK, das häufig in academischen Bereichen (Forschung und Lehre) eingesetzt wird, ist spaCy eher für Produktionsnutzung entwickelt."
      ],
      "metadata": {
        "id": "25wunZzUmSgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenisierung mit NLTK"
      ],
      "metadata": {
        "id": "og_8WhYQnjkk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jpbNxEpGm7nR"
      },
      "outputs": [],
      "source": [
        "!pip install -q nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bei NLTK kann man nur notwendige Modelle installieren. Die Liste der Modelle/Korpora ist [hier](https://www.nltk.org/nltk_data/) zu finden.\n",
        "Für Tokenisierung gibt es ein Modell:\n",
        ">Punkt Tokenizer Models [ download | source ]\n",
        "id: punkt; size: 13905355; author: Jan Strunk; copyright: ; license: ;\n",
        "\n",
        "Um ein Modell herunterzuladen, gibt man in \"download\"-Methode die ID des Modells ein:\n",
        "\n",
        "\n",
        "```python\n",
        "import nltk\n",
        "nltk.download(\"punkt\")\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "F6Hr-fUOtHp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcVpPIsfpUpB",
        "outputId": "0ed80e64-10ae-4f81-ffdc-289e0c7229ce"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "# \"\\n\" steht für Zeilenumbruch\n",
        "s = '''Good muffins cost $3.88\\nin New York.  Please buy me\n",
        "... two of them.\\n\\nThanks.'''\n",
        "word_tokenize(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1-FtcYDnn39",
        "outputId": "77f54345-159b-4fd2-a325-cfe05a4a6ac1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Good',\n",
              " 'muffins',\n",
              " 'cost',\n",
              " '$',\n",
              " '3.88',\n",
              " 'in',\n",
              " 'New',\n",
              " 'York',\n",
              " '.',\n",
              " 'Please',\n",
              " 'buy',\n",
              " 'me',\n",
              " '...',\n",
              " 'two',\n",
              " 'of',\n",
              " 'them',\n",
              " '.',\n",
              " 'Thanks',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Der Toknizer hat auch Regex-basierte Tokenisierungsmethode - Dabei werden Spatium und Interpunktion berücksichtigt."
      ],
      "metadata": {
        "id": "dluFdukKKmyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import wordpunct_tokenize\n",
        "wordpunct_tokenize(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUFtCmvrKhkk",
        "outputId": "bcc5dcf9-f59a-4b9d-d25f-195ccba2c709"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Good',\n",
              " 'muffins',\n",
              " 'cost',\n",
              " '$',\n",
              " '3',\n",
              " '.',\n",
              " '88',\n",
              " 'in',\n",
              " 'New',\n",
              " 'York',\n",
              " '.',\n",
              " 'Please',\n",
              " 'buy',\n",
              " 'me',\n",
              " '...',\n",
              " 'two',\n",
              " 'of',\n",
              " 'them',\n",
              " '.',\n",
              " 'Thanks',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "punkt-Tokenizer enthält auch Sentence-Tokenizer, mit dem man ein Sätze in einem Korpus trennt. Wenn man danach word-tokenizer verwendet, erhalt man die Tokens in 2d-Array wie unten."
      ],
      "metadata": {
        "id": "xJvwdeyLIXQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "sent_tokenize(s)\n",
        "[word_tokenize(t) for t in sent_tokenize(s)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tazio_UEIDDI",
        "outputId": "8edb9ab2-d447-4581-ab21-e9832c68d7b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Good', 'muffins', 'cost', '$', '3.88', 'in', 'New', 'York', '.'],\n",
              " ['Please', 'buy', 'me', '...', 'two', 'of', 'them', '.'],\n",
              " ['Thanks', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SpaCy\n",
        "\n",
        "spaCy bietet an sich einen Tokenizer an. Aber man kann auch ein vortrainiertes Sprachmodell herunterladen und dies zur Tokenisierung anwenden.\n",
        "Hier sehen wir die 2 Methoden."
      ],
      "metadata": {
        "id": "CHSxnA_xqb62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q spacy"
      ],
      "metadata": {
        "id": "mw1Dm5PjqfQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "nlp = English()\n",
        "tokenizer = nlp.tokenizer\n",
        "s = '''Good muffins cost $3.88\\nin New York.  Please buy me\n",
        "... two of them.\\n\\nThanks.'''\n",
        "tokens = tokenizer(s)\n",
        "\n",
        "# Doc-Objekt wird zurückgegeben\n",
        "print(\"Einfaches Doc-Objekt: \")\n",
        "print(tokens)\n",
        "\n",
        "print(\"\\nEinzelne Token:\")\n",
        "for token in tokens:\n",
        "    print(token.text)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl8wKsBIra-j",
        "outputId": "b78d0bde-f53b-44e3-c9c8-b774337b1de4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Einfaches Doc-Objekt: \n",
            "Good muffins cost $3.88\n",
            "in New York.  Please buy me\n",
            "... two of them.\n",
            "\n",
            "Thanks.\n",
            "\n",
            "Einzelne Token:\n",
            "Good\n",
            "muffins\n",
            "cost\n",
            "$\n",
            "3.88\n",
            "\n",
            "\n",
            "in\n",
            "New\n",
            "York\n",
            ".\n",
            " \n",
            "Please\n",
            "buy\n",
            "me\n",
            "\n",
            "\n",
            "...\n",
            "two\n",
            "of\n",
            "them\n",
            ".\n",
            "\n",
            "\n",
            "\n",
            "Thanks\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "from spacy.cli import download\n",
        "\n",
        "download(\"en_core_web_md\")\n",
        "\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "s = '''Good muffins cost $3.88\\nin New York.  Please buy me\n",
        "... two of them.\\n\\nThanks.'''\n",
        "doc = nlp(s)\n",
        "for token in doc:\n",
        "    desc = token.text + \", \" + token.pos_\n",
        "    print(desc)\n",
        "\n",
        "displacy.render(doc, jupyter=True, style=\"dep\", options={\"compact\":True})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "BfJMa6pzwV7c",
        "outputId": "7afbeb8f-f169-4307-8c0f-cf19c1cdd1fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_md')\n",
            "Good, ADJ\n",
            "muffins, NOUN\n",
            "cost, VERB\n",
            "$, SYM\n",
            "3.88, NUM\n",
            "\n",
            ", SPACE\n",
            "in, ADP\n",
            "New, PROPN\n",
            "York, PROPN\n",
            "., PUNCT\n",
            " , SPACE\n",
            "Please, INTJ\n",
            "buy, VERB\n",
            "me, PRON\n",
            "\n",
            ", SPACE\n",
            "..., PUNCT\n",
            "two, NUM\n",
            "of, ADP\n",
            "them, PRON\n",
            "., PUNCT\n",
            "\n",
            "\n",
            ", SPACE\n",
            "Thanks, NOUN\n",
            "., PUNCT\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"e880cdca95754e57b39400a3da727f19-0\" class=\"displacy\" width=\"2900\" height=\"362.0\" direction=\"ltr\" style=\"max-width: none; height: 362.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Good</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">muffins</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">cost</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">$</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">SYM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">3.88</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">\n",
              "</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">SPACE</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">New</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">York.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">PUNCT</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\"> </tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">SPACE</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1550\">Please</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1550\">INTJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1700\">buy</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1700\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\">me</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2000\">\n",
              "...</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2000\">SPACE</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">two</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2300\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2300\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2450\">them.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2450\">PUNCT</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2600\">\n",
              "\n",
              "</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2600\">SPACE</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2750\">Thanks.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2750\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-0\" stroke-width=\"2px\" d=\"M62,227.0 62,202.0 194.0,202.0 194.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M62,229.0 L58,221.0 66,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-1\" stroke-width=\"2px\" d=\"M212,227.0 212,202.0 344.0,202.0 344.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M212,229.0 L208,221.0 216,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-2\" stroke-width=\"2px\" d=\"M512,227.0 512,202.0 644.0,202.0 644.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M512,229.0 L508,221.0 516,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-3\" stroke-width=\"2px\" d=\"M362,227.0 362,177.0 647.0,177.0 647.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M647.0,229.0 L651.0,221.0 643.0,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-4\" stroke-width=\"2px\" d=\"M662,227.0 662,202.0 794.0,202.0 794.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M794.0,229.0 L798.0,221.0 790.0,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-5\" stroke-width=\"2px\" d=\"M662,227.0 662,177.0 947.0,177.0 947.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M947.0,229.0 L951.0,221.0 943.0,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-6\" stroke-width=\"2px\" d=\"M1112,227.0 1112,202.0 1244.0,202.0 1244.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1112,229.0 L1108,221.0 1116,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-7\" stroke-width=\"2px\" d=\"M362,227.0 362,152.0 1250.0,152.0 1250.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1250.0,229.0 L1254.0,221.0 1246.0,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-8\" stroke-width=\"2px\" d=\"M1262,227.0 1262,202.0 1394.0,202.0 1394.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1394.0,229.0 L1398.0,221.0 1390.0,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-9\" stroke-width=\"2px\" d=\"M1562,227.0 1562,202.0 1694.0,202.0 1694.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">intj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1562,229.0 L1558,221.0 1566,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-10\" stroke-width=\"2px\" d=\"M1712,227.0 1712,202.0 1844.0,202.0 1844.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1844.0,229.0 L1848.0,221.0 1840.0,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-11\" stroke-width=\"2px\" d=\"M1862,227.0 1862,202.0 1994.0,202.0 1994.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1994.0,229.0 L1998.0,221.0 1990.0,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-12\" stroke-width=\"2px\" d=\"M1712,227.0 1712,177.0 2147.0,177.0 2147.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2147.0,229.0 L2151.0,221.0 2143.0,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-13\" stroke-width=\"2px\" d=\"M2162,227.0 2162,202.0 2294.0,202.0 2294.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2294.0,229.0 L2298.0,221.0 2290.0,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-14\" stroke-width=\"2px\" d=\"M1712,227.0 1712,152.0 2450.0,152.0 2450.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">punct</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2450.0,229.0 L2454.0,221.0 2446.0,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e880cdca95754e57b39400a3da727f19-0-15\" stroke-width=\"2px\" d=\"M2462,227.0 2462,202.0 2594.0,202.0 2594.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e880cdca95754e57b39400a3da727f19-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2594.0,229.0 L2598.0,221.0 2590.0,221.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wenn die Satz-Ebene berücksichtigt werden soll, soll ein Schritt vor der Tokenisierung hineingeschoben werden."
      ],
      "metadata": {
        "id": "4Odv9SN1FmsQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dieser Schritt ist bereits oben ausgeführt. Deshalb muss er hier nicht nochmals ausgeführt werden.\n",
        "#from spacy.cli import download\n",
        "#download(\"en_core_web_md\")"
      ],
      "metadata": {
        "id": "rqH4KjlAF7LT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy.lang.en import English\n",
        "\n",
        "nlp_sent = English()\n",
        "nlp_sent.add_pipe(\"sentencizer\")\n",
        "s = '''Good muffins cost $3.88\\nin New York.  Please buy me\n",
        "... two of them.\\n\\nThanks.'''\n",
        "doc = nlp_sent(s)\n",
        "print(list(doc.sents))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqNcfYeJEBmu",
        "outputId": "d178aea1-d20d-475c-c620-4c8ab15d088b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Good muffins cost $3.88\n",
            "in New York.,  Please buy me\n",
            "... two of them., \n",
            "\n",
            "Thanks.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "full_arr = []\n",
        "\n",
        "for s in doc.sents:\n",
        "    s = str(s)\n",
        "    sent_analyse = nlp(s)\n",
        "    sent_arr = []\n",
        "    for token in sent_analyse:\n",
        "        sent_arr.append(token.text)\n",
        "    full_arr.append(sent_arr)\n",
        "\n",
        "print(full_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9jKKVkhESJH",
        "outputId": "483e2bc1-debc-413d-8f4b-148de025438d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['Good', 'muffins', 'cost', '$', '3.88', '\\n', 'in', 'New', 'York', '.'], [' ', 'Please', 'buy', 'me', '\\n', '...', 'two', 'of', 'them', '.'], ['\\n\\n', 'Thanks', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Probabilistic Tokenization mit tiktoken\n",
        "\n",
        "Um ein Beispiel für Probabilistic Tokenisierung zu sehen, führen wir hier noch tiktoken ein. Tiktoken ist eine Library, die von OpenAI als open source angeboten ist.\n",
        "\n",
        "Bei der probabilistic Tokenization, die als Vorprozess für LLM verwendet wird, werden die Texte in die nummerischen Tokens. (s. Byte pair encoding ([Gage, Philip. \"A New Algorithm for Data Compression\". 1994](http://www.pennelynn.com/Documents/CUJ/HTML/94HTML/19940045.HTM)))\n",
        "\n",
        "\n",
        "Die konkrete Anwendung der Library \"tiktoken\" findet man auch im Cookbook von OpenAI:\n",
        "https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "\n"
      ],
      "metadata": {
        "id": "dpVVsH6g_ejo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43sgPF6KAZOc",
        "outputId": "21fac62c-f430-44f5-8c65-67d7ec58db1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.7 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n",
            "Installing collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es sind 3 Encodings für Tokenisierung. Die Encodings entsprechen den OpenAL Modell folgendermassen:\n",
        "\n",
        "\n",
        "|Encoding name\t | OpenAI models|\n",
        "|----------------|----------------|\n",
        "|cl100k_base\t   |gpt-4, gpt-3.5-turbo, text-embedding-ada-002|\n",
        "|p50k_base\t     |Codex models, text-davinci-002, text-davinci-003|\n",
        "|r50k_base (or gpt2)\t|GPT-3 models like davinci|\n",
        "\n"
      ],
      "metadata": {
        "id": "AH_MeBxTJUrF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "s = '''Good muffins cost $3.88\\nin New York.  Please buy me\n",
        "... two of them.\\n\\nThanks.'''\n",
        "chatgpt_tokens = encoding.encode(s)\n",
        "print(chatgpt_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G9T0eEvAbPO",
        "outputId": "24525746-46dd-49e7-f164-0295dede29b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15571, 55404, 1354, 2853, 400, 18, 13, 2421, 198, 258, 1561, 4356, 13, 220, 5321, 3780, 757, 198, 1131, 1403, 315, 1124, 382, 12947, 13]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diese Tokens können als byte string für die menschlichen Augen lesbar gemacht werden."
      ],
      "metadata": {
        "id": "4L2cmALuICAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "[encoding.decode_single_token_bytes(token) for token in chatgpt_tokens]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6MSI_x8BS8x",
        "outputId": "f039123e-01df-4609-cf59-43964da8e670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[b'Good',\n",
              " b' muff',\n",
              " b'ins',\n",
              " b' cost',\n",
              " b' $',\n",
              " b'3',\n",
              " b'.',\n",
              " b'88',\n",
              " b'\\n',\n",
              " b'in',\n",
              " b' New',\n",
              " b' York',\n",
              " b'.',\n",
              " b' ',\n",
              " b' Please',\n",
              " b' buy',\n",
              " b' me',\n",
              " b'\\n',\n",
              " b'...',\n",
              " b' two',\n",
              " b' of',\n",
              " b' them',\n",
              " b'.\\n\\n',\n",
              " b'Thanks',\n",
              " b'.']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "... Und die byte strings können wieder in normale Strings umgewandelt werden."
      ],
      "metadata": {
        "id": "CwcjxGpFKMvU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in chatgpt_tokens:\n",
        "    token = encoding.decode_single_token_bytes(token)\n",
        "    print(token.decode(\"UTF-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB2mtqgeIR6h",
        "outputId": "0fcea405-b4c7-4d34-fef0-33e13266fa75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good\n",
            " muff\n",
            "ins\n",
            " cost\n",
            " $\n",
            "3\n",
            ".\n",
            "88\n",
            "\n",
            "\n",
            "in\n",
            " New\n",
            " York\n",
            ".\n",
            " \n",
            " Please\n",
            " buy\n",
            " me\n",
            "\n",
            "\n",
            "...\n",
            " two\n",
            " of\n",
            " them\n",
            ".\n",
            "\n",
            "\n",
            "Thanks\n",
            ".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Quiz\n",
        "\n",
        "... Tokenisierung selber ausprobieren!\n",
        "1. Wähle zuerst eine Library, mit der du Tokenisierung durchführen willst.\n",
        "1. Dann eigene Sätze von irgendwo holen.\n",
        "1. Selber Code schreiben\n",
        "1. Wenn man will, kann man auch die Satz-Ebene trennen.\n",
        "\n",
        "Hints:\n",
        "\n",
        "- sent_tokenize und word_tokenize Methode in NLTK kann weitere Parameters wie language nehmen. Falls man die Texte nicht auf Englisch hat, kann man die Parameters ändern. Hier die Beschreibungen für [sent_tokenize](https://www.nltk.org/_modules/nltk/tokenize.html#sent_tokenize) und [word_tokenize](https://www.nltk.org/_modules/nltk/tokenize.html#word_tokenize)\n",
        "- spaCy bietet Modelsets für unterschiedliche Sprachen an. Siehe [hier](https://spacy.io/usage/models#languages)\n"
      ],
      "metadata": {
        "id": "Z76E_rIrLlsV"
      }
    }
  ]
}