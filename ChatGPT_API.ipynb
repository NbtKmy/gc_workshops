{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMLILTyjnxBhrPSnurwN68w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NbtKmy/gc_workshops/blob/main/ChatGPT_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT API\n",
        "\n",
        "Seit M√§rz 2023 bietet OpenAI die API f√ºr ChatGPT (siehe [den Link](https://openai.com/blog/introducing-chatgpt-and-whisper-apis)) an. Hier probieren wir die API-Schnittstelle von ChatGPT aus.\n",
        "\n",
        "F√ºr die Nutzung der API muss man einen Account bei OpenAI erstellen und den **kostenpflichtigen** Plan nehmen. Preise der Nutzung ist [hier](https://openai.com/pricing) dokumentiert. \n",
        "\n",
        "Demnach:\n",
        "\n",
        "| Model\t| Usage |\n",
        "|-------|------------------------|\n",
        "| gpt-3.5-turbo\t| $0.002 / 1K tokens |\n",
        "\n",
        "Der Preis ist nicht so hoch, aber man muss Kreditkarteninformation hinterlegen. \n",
        "Wenn man einen Account bei OpenAI ganz neu gemacht hat, erh√§lt man ausserdem Guthaben f√ºr 18 US-Doller, die 3 Monaten nach der Erstellung des Accounts abl√§uft.\n",
        "\n",
        "## Token?\n",
        "Zur Z√§hlung der Tokens wird in der Dokumentation folgendermassen erkl√§rt: \n",
        "> Language models read text in chunks called tokens. In English, a token can be as short as one character or as long as one word (e.g., a or apple), and in some languages tokens can be even shorter than one character or even longer than one word.\n",
        "> [...]\n",
        "> Both input and output tokens count toward these quantities. For example, if your API call used 10 tokens in the message input and you received 20 tokens in the message output, you would be billed for 30 tokens.\n",
        "\n",
        "(Stand: 6. M√§rz 2023. Aus: https://platform.openai.com/docs/guides/chat/managing-tokens)\n",
        "\n",
        "## Nutzung der eingegebenen Daten?\n",
        "\n",
        "Laut der Dokumentation werden die durch API eingegebenen Daten/Texte nicht automatisch f√ºr die Verbesserung/Training des KI-Modells verwendet. \n",
        "\n",
        "(Stand: 6. M√§rz 2023. Siehe: https://platform.openai.com/docs/data-usage-policies)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SOllXGshgH2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wie siehen die Tokens aus?\n",
        "\n",
        "Bevor man mit der API beginnt, betrachten wir zuerst, wie die Tokens bei ChatGPT aussiehen. \n",
        "Im folgenden Abschnitt kann man beliebige Texte eingeben, um die Zahlung der Tokens zu erfahren. \n",
        "Dadurch k√∂nnen wir vielleicht Gef√ºhl bekommen, wie viel Texte/S√§tze wie viel Tokens entsprechen...\n",
        "\n",
        "OpenAI bietet daf√ºr Python-Library, tiktoken, an. Mit Hilfe von tiktoken kann man die Tokenzahlen bei ChatGPT er√∂rtern."
      ],
      "metadata": {
        "id": "sBsEep40HzML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U tiktoken"
      ],
      "metadata": {
        "id": "DPTVy9az45KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
        "text_to_tokens = ''#@param{type:'string'}\n",
        "\n",
        "tokens = encoding.encode(text_to_tokens)\n",
        "print('Zahl der Tokens: ' + str(len(tokens)))\n",
        "print(tokens)\n",
        "\n",
        "\n",
        "for token in tokens:\n",
        "    bytes_token = encoding.decode_single_token_bytes(token)\n",
        "    string_token = bytes_token.decode('utf-8', 'ignore')\n",
        "    print(str(bytes_token) + ' = ' + string_token)\n",
        "    \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8uowWsey48bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChatGPT API verwenden"
      ],
      "metadata": {
        "id": "h2rd_mFFI-il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai "
      ],
      "metadata": {
        "id": "4pbFlEEhjouv"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hier braucht man den eigenen API-Key. **Der API-Key muss vor fremden Leuten gesch√ºtzt sein!!**"
      ],
      "metadata": {
        "id": "zmsEphhTEmbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "\n",
        "my_api_key = 'dein API-Key'#@param{type:'string'} \n",
        "openai.api_key = my_api_key\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5oNWXnZPjwKe"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Einstellung des ChatBot: https://platform.openai.com/docs/guides/chat/introduction\n",
        "\n",
        "Die Beschreibung f√ºr das Parameter \"temperature\" ist hier zu finden: https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature\n",
        "\n",
        "temperature kann einen Wert zwischen 0 und 2 [ich glaube, hier ist 1 gemeint] nehmen. Der tiefe Wert bedeutet, dass die Antwort der KI akurrat wird. Der hohe Wert von temperature f√ºhrt zur freien/kreativen Antwort.\n",
        "\n",
        "Um das Gespr√§ch zu beenden, tippe \"Gespr√§ch beenden\" in Prompt"
      ],
      "metadata": {
        "id": "R3ebs6QlJt-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "system_msg = 'Du bist ein freundlicher KI-ChatBot.\\\n",
        "    Dein Name ist Robita.'\n",
        "messages.append({'role': 'system', 'content': system_msg})\n",
        "print('Sag etwas zu Robita')\n",
        "while True:\n",
        "    message = input ('üôã Human: ')\n",
        "    \n",
        "    messages.append ({'role': 'user', 'content': message})\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model='gpt-3.5-turbo',\n",
        "        messages=messages,\n",
        "        temperature=0.8,\n",
        "    )\n",
        "    reply = response['choices'][0]['message']['content']\n",
        "    messages.append({'role': 'assistant', 'content': reply})\n",
        "    print('---\\nü§ñ Robita: ' + reply + '\\n---')\n",
        "\n",
        "    if message == 'Gespr√§ch beenden':\n",
        "        break\n"
      ],
      "metadata": {
        "id": "Ni5BRgVskYTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Referenz\n",
        "\n",
        "Dokumentation f√ºr Chat Completions (ChatGPT)\n",
        "https://platform.openai.com/docs/guides/chat/chat-completions-beta\n",
        "\n",
        "Sangmin Ahn: ChatGPT„ÅÆAPI„Çí„Ç≥„Éû„É≥„Éâ„Éó„É≠„É≥„Éó„Éà„Åã„ÇâÂÆüË£Ö„Åô„ÇãÊñπÊ≥ï\n",
        "https://note.com/sangmin/n/ndcacb7b08f40"
      ],
      "metadata": {
        "id": "xTYCpvmaGC5d"
      }
    }
  ]
}