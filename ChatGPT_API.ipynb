{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzOWFqmzmVFojhmRjP0xVL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NbtKmy/gc_workshops/blob/main/ChatGPT_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT API\n",
        "\n",
        "Seit MÃ¤rz 2023 bietet OpenAI die API fÃ¼r ChatGPT (siehe [den Link](https://openai.com/blog/introducing-chatgpt-and-whisper-apis)) an. Hier probieren wir die API-Schnittstelle von ChatGPT aus.\n",
        "(Es gab Update im Juni 2023. Seitdem sind unterschiedliche Modelle angeboten. Siehe [\"Models overview\"-Seite](https://platform.openai.com/docs/models/overview))\n",
        "\n",
        "\n",
        "FÃ¼r die Nutzung der API muss man einen Account bei OpenAI erstellen und den **kostenpflichtigen** Plan nehmen. Preise der Nutzung ist [hier](https://openai.com/pricing) dokumentiert.\n",
        "\n",
        "Demnach:\n",
        "\n",
        "| Model\t| Usage input | Usage output |\n",
        "|---------------|---------------------|---------------------|\n",
        "| gpt-3.5-turbo\t|  \\$0.0015/1K tokens  |  \\$0.002 / 1K tokens |\n",
        "| gpt-3.5-turbo-16k | \\$0.003 / 1K tokens | \\$0.004 / 1K tokens |\n",
        "| gpt-4 (8k tokens) | \\$0.03 / 1K tokens | \\$0.06 / 1K tokens |\n",
        "| gpt-4-32k | \\$0.06 / 1K tokens | \\$0.12 / 1K tokens |\n",
        "\n",
        "__Stand: 26.09.2023. Aktuelle Preise bitte immer auf der [offiziellen Seite](https://openai.com/pricing) Ã¼berprÃ¼fen__\n",
        "\n",
        "Der Preis fÃ¼r gpt-3.5-turbo ist nicht so hoch, aber man muss Kreditkarteninformation hinterlegen.\n",
        "Wenn man einen Account bei OpenAI ganz neu gemacht hat, erhÃ¤lt man ausserdem Guthaben fÃ¼r 18 US-Doller, die 3 Monaten nach der Erstellung des Accounts ablÃ¤uft.\n",
        "\n",
        "## Token?\n",
        "Zur ZÃ¤hlung der Tokens wird in der Dokumentation folgendermassen erklÃ¤rt:\n",
        "> Language models read text in chunks called tokens. In English, a token can be as short as one character or as long as one word (e.g., a or apple), and in some languages tokens can be even shorter than one character or even longer than one word.\n",
        "> [...]\n",
        "> Both input and output tokens count toward these quantities. For example, if your API call used 10 tokens in the message input and you received 20 tokens in the message output, you would be billed for 30 tokens.\n",
        "\n",
        "(Stand: 6. MÃ¤rz 2023. Aus: https://platform.openai.com/docs/guides/chat/managing-tokens)\n",
        "\n",
        "## Nutzung der eingegebenen Daten?\n",
        "\n",
        "Laut der Dokumentation werden die durch API eingegebenen Daten/Texte nicht automatisch fÃ¼r die Verbesserung/Training des KI-Modells verwendet.\n",
        "\n",
        "(Stand: 6. MÃ¤rz 2023. Siehe: https://platform.openai.com/docs/data-usage-policies)\n",
        "\n",
        "\n",
        "## Unterschiedliche LLMs testen\n",
        "AI Playground\n",
        "https://play.vercel.ai/"
      ],
      "metadata": {
        "id": "SOllXGshgH2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wie siehen die Tokens aus?\n",
        "\n",
        "Bevor man mit der API beginnt, betrachten wir zuerst, wie die Tokens bei ChatGPT aussiehen.\n",
        "Im folgenden Abschnitt kann man beliebige Texte eingeben, um die Zahlung der Tokens zu erfahren.\n",
        "Dadurch kÃ¶nnen wir vielleicht GefÃ¼hl bekommen, wie viel Texte/SÃ¤tze wie viel Tokens entsprechen...\n",
        "\n",
        "OpenAI bietet dafÃ¼r Python-Library, tiktoken, an. Mit Hilfe von tiktoken kann man die Tokenzahlen bei ChatGPT erÃ¶rtern."
      ],
      "metadata": {
        "id": "sBsEep40HzML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q tiktoken"
      ],
      "metadata": {
        "id": "DPTVy9az45KJ",
        "outputId": "7f70b8a9-779c-4211-a607-8e594fbdd76f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.2/1.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
        "text_to_tokens = ''#@param{type:'string'}\n",
        "\n",
        "tokens = encoding.encode(text_to_tokens)\n",
        "print('Zahl der Tokens: ' + str(len(tokens)))\n",
        "print(tokens)\n",
        "\n",
        "\n",
        "for token in tokens:\n",
        "    bytes_token = encoding.decode_single_token_bytes(token)\n",
        "    string_token = bytes_token.decode('utf-8', 'ignore')\n",
        "    print(str(bytes_token) + ' = ' + string_token)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8uowWsey48bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChatGPT API verwenden"
      ],
      "metadata": {
        "id": "h2rd_mFFI-il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "4pbFlEEhjouv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d643e777-6352-464e-d748-4d109e4afe8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hier braucht man den eigenen API-Key. **Der API-Key muss vor fremden Leuten geschÃ¼tzt sein!!**"
      ],
      "metadata": {
        "id": "zmsEphhTEmbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "\n",
        "my_api_key = ''#@param{type:'string'}\n",
        "openai.api_key = my_api_key\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5oNWXnZPjwKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Einstellung des ChatBot: https://platform.openai.com/docs/guides/chat/introduction\n",
        "\n",
        "Die Beschreibung fÃ¼r das Parameter \"temperature\" ist hier zu finden: https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature\n",
        "\n",
        "temperature kann einen Wert zwischen 0 und 2 nehmen. Der tiefe Wert bedeutet, dass die Antwort der KI akurrat wird. Der hohe Wert von temperature fÃ¼hrt zur freien/kreativen Antwort.\n",
        "\n",
        "Um das GesprÃ¤ch zu beenden, tippe \"GesprÃ¤ch beenden\" in Prompt"
      ],
      "metadata": {
        "id": "R3ebs6QlJt-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "system_msg = 'Du bist ein freundlicher KI-ChatBot.\\\n",
        "    Dein Name ist Robita.'\n",
        "messages.append({'role': 'system', 'content': system_msg})\n",
        "print('Sag etwas zu Robita')\n",
        "while True:\n",
        "    message = input ('ğŸ™‹ Human: ')\n",
        "\n",
        "    messages.append ({'role': 'user', 'content': message})\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model='gpt-3.5-turbo',\n",
        "        messages=messages,\n",
        "        temperature=0.8,\n",
        "    )\n",
        "    reply = response['choices'][0]['message']['content']\n",
        "    messages.append({'role': 'assistant', 'content': reply})\n",
        "    print('---\\nğŸ¤– Robita: ' + reply + '\\n---')\n",
        "\n",
        "    if message == 'GesprÃ¤ch beenden':\n",
        "        break\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ni5BRgVskYTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gTTS"
      ],
      "metadata": {
        "id": "pzT-tXNhhX1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "from IPython.display import display\n",
        "from io import BytesIO\n",
        "from tempfile import TemporaryFile\n",
        "\n",
        "\n",
        "\n",
        "tts = gTTS('hallo, mein name ist totoro. Heute ist sonnig. Was kann ich fÃ¼r dich tun?', lang='de')\n",
        "f = TemporaryFile()\n",
        "tts.write_to_fp(f)\n",
        "f.seek(0)\n",
        "aud = Audio(f.read(), autoplay=True)\n",
        "display(aud)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "JCXn0xOAhcur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "from IPython.display import display\n",
        "from io import BytesIO\n",
        "from tempfile import TemporaryFile\n",
        "\n",
        "import openai\n",
        "\n",
        "\n",
        "def speech(txt):\n",
        "\n",
        "    tts = gTTS(txt, lang='de')\n",
        "    f = TemporaryFile()\n",
        "    tts.write_to_fp(f)\n",
        "    f.seek(0)\n",
        "    aud = Audio(f.read(), autoplay=True)\n",
        "    display(aud)\n",
        "    f.close()\n",
        "\n",
        "\n",
        "my_api_key = ''#@param{type:'string'}\n",
        "openai.api_key = my_api_key\n",
        "\n",
        "messages = []\n",
        "system_msg = 'Du bist ein freundlicher KI-ChatBot.\\\n",
        "    Dein Name ist Robita.'\n",
        "messages.append({'role': 'system', 'content': system_msg})\n",
        "first_message = 'Sag etwas zu Robita'\n",
        "print(first_message)\n",
        "speech(first_message)\n",
        "\n",
        "while True:\n",
        "    message = input ('ğŸ™‹ Human: ')\n",
        "\n",
        "    messages.append ({'role': 'user', 'content': message})\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model='gpt-3.5-turbo',\n",
        "        messages=messages,\n",
        "        temperature=0.8,\n",
        "    )\n",
        "    reply = response['choices'][0]['message']['content']\n",
        "    messages.append({'role': 'assistant', 'content': reply})\n",
        "    print('---\\nğŸ¤– Robita: ' + reply + '\\n---')\n",
        "    speech(reply)\n",
        "    if message == 'GesprÃ¤ch beenden':\n",
        "        break\n",
        "\n"
      ],
      "metadata": {
        "id": "Uh4IR5P5rhnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GesprÃ¤ch mit ChatGPT\n",
        "\n",
        "OpenAI bietet \"Whisper API\", API fÃ¼r Speech-to-Text, an. Mit dieser API probieren wir ein \"GesprÃ¤ch\" mit ChatGPT."
      ],
      "metadata": {
        "id": "i-eS5w9NkKvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gTTS openai gradio numpy scipy"
      ],
      "metadata": {
        "id": "1MaH0oklEguO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "my_api_key = ''#@param{type:'string'}\n",
        "openai.api_key = my_api_key"
      ],
      "metadata": {
        "id": "sGgRXKHLmjU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "from IPython.display import display\n",
        "from io import BytesIO\n",
        "from tempfile import TemporaryFile\n",
        "import time\n",
        "\n",
        "import openai\n",
        "import gradio as gr\n",
        "\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "\n",
        "\n",
        "def speech(txt):\n",
        "\n",
        "    tts = gTTS(txt, lang='de')\n",
        "    f = TemporaryFile()\n",
        "    tts.write_to_fp(f)\n",
        "    f.seek(0)\n",
        "    aud = Audio(f.read(), autoplay=True)\n",
        "    display(aud)\n",
        "    f.close()\n",
        "\n",
        "def speech_to_text(audio):\n",
        "\n",
        "    # Gradio.Audio gibt die Aufnahme durch Microphon als numpy.Array\n",
        "    # FÃ¼r whisper muss diese numpy.Array-Daten in ein passendes Format umgewandelt werden\n",
        "    rate, audio_data = audio\n",
        "    scaled = np.int16(audio_data / np.max(np.abs(audio_data)) * 32767)\n",
        "    write('test.wav', rate, scaled)\n",
        "    audio_file = open('test.wav', 'rb')\n",
        "    transcript = openai.Audio.transcribe('whisper-1', audio_file)\n",
        "\n",
        "    return transcript.text\n",
        "\n",
        "\n",
        "def audio_chat(audio, messages_stats):\n",
        "\n",
        "\n",
        "    speech_text = speech_to_text(audio)\n",
        "    message = 'ğŸ™‹ Human: ' + speech_text\n",
        "\n",
        "    messages_stats.append ({'role': 'user', 'content': speech_text})\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model='gpt-3.5-turbo',\n",
        "        messages=messages_stats,\n",
        "        temperature=0.8,\n",
        "    )\n",
        "    reply = response['choices'][0]['message']['content']\n",
        "\n",
        "    speech(reply)\n",
        "    messages_stats.append({'role': 'assistant', 'content': reply})\n",
        "    message += '\\nğŸ¤– Robita: ' + reply + '\\n---'\n",
        "\n",
        "\n",
        "    return message, messages_stats\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    messages = []\n",
        "    system_msg = 'Du bist ein freundlicher KI-ChatBot. Dein Name ist Robita.'\n",
        "    messages.append({'role': 'system', 'content': system_msg})\n",
        "    messages_stats = gr.State(value=messages)\n",
        "    first_message = 'Sag etwas zu Robita'\n",
        "    speech(first_message)\n",
        "\n",
        "\n",
        "    gr.Interface(\n",
        "        title = 'Chatten mit ChatGPT',\n",
        "        fn=audio_chat,\n",
        "\n",
        "        inputs=[\n",
        "            gr.Audio(source='microphone'),\n",
        "            messages_stats\n",
        "        ],\n",
        "        outputs=[\n",
        "            'textbox',\n",
        "            messages_stats\n",
        "        ],\n",
        "        live=True\n",
        "    ).launch()"
      ],
      "metadata": {
        "id": "TcPZI3aNG-k_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Referenz\n",
        "\n",
        "Dokumentation fÃ¼r Chat Completions (ChatGPT)\n",
        "https://platform.openai.com/docs/guides/chat/chat-completions-beta\n",
        "\n"
      ],
      "metadata": {
        "id": "xTYCpvmaGC5d"
      }
    }
  ]
}