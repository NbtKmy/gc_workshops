{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzOWFqmzmVFojhmRjP0xVL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NbtKmy/gc_workshops/blob/main/ChatGPT_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ChatGPT API\n",
        "\n",
        "Seit März 2023 bietet OpenAI die API für ChatGPT (siehe [den Link](https://openai.com/blog/introducing-chatgpt-and-whisper-apis)) an. Hier probieren wir die API-Schnittstelle von ChatGPT aus.\n",
        "(Es gab Update im Juni 2023. Seitdem sind unterschiedliche Modelle angeboten. Siehe [\"Models overview\"-Seite](https://platform.openai.com/docs/models/overview))\n",
        "\n",
        "\n",
        "Für die Nutzung der API muss man einen Account bei OpenAI erstellen und den **kostenpflichtigen** Plan nehmen. Preise der Nutzung ist [hier](https://openai.com/pricing) dokumentiert.\n",
        "\n",
        "Demnach:\n",
        "\n",
        "| Model\t| Usage input | Usage output |\n",
        "|---------------|---------------------|---------------------|\n",
        "| gpt-3.5-turbo\t|  \\$0.0015/1K tokens  |  \\$0.002 / 1K tokens |\n",
        "| gpt-3.5-turbo-16k | \\$0.003 / 1K tokens | \\$0.004 / 1K tokens |\n",
        "| gpt-4 (8k tokens) | \\$0.03 / 1K tokens | \\$0.06 / 1K tokens |\n",
        "| gpt-4-32k | \\$0.06 / 1K tokens | \\$0.12 / 1K tokens |\n",
        "\n",
        "__Stand: 26.09.2023. Aktuelle Preise bitte immer auf der [offiziellen Seite](https://openai.com/pricing) überprüfen__\n",
        "\n",
        "Der Preis für gpt-3.5-turbo ist nicht so hoch, aber man muss Kreditkarteninformation hinterlegen.\n",
        "Wenn man einen Account bei OpenAI ganz neu gemacht hat, erhält man ausserdem Guthaben für 18 US-Doller, die 3 Monaten nach der Erstellung des Accounts abläuft.\n",
        "\n",
        "## Token?\n",
        "Zur Zählung der Tokens wird in der Dokumentation folgendermassen erklärt:\n",
        "> Language models read text in chunks called tokens. In English, a token can be as short as one character or as long as one word (e.g., a or apple), and in some languages tokens can be even shorter than one character or even longer than one word.\n",
        "> [...]\n",
        "> Both input and output tokens count toward these quantities. For example, if your API call used 10 tokens in the message input and you received 20 tokens in the message output, you would be billed for 30 tokens.\n",
        "\n",
        "(Stand: 6. März 2023. Aus: https://platform.openai.com/docs/guides/chat/managing-tokens)\n",
        "\n",
        "## Nutzung der eingegebenen Daten?\n",
        "\n",
        "Laut der Dokumentation werden die durch API eingegebenen Daten/Texte nicht automatisch für die Verbesserung/Training des KI-Modells verwendet.\n",
        "\n",
        "(Stand: 6. März 2023. Siehe: https://platform.openai.com/docs/data-usage-policies)\n",
        "\n",
        "\n",
        "## Unterschiedliche LLMs testen\n",
        "AI Playground\n",
        "https://play.vercel.ai/"
      ],
      "metadata": {
        "id": "SOllXGshgH2O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Wie siehen die Tokens aus?\n",
        "\n",
        "Bevor man mit der API beginnt, betrachten wir zuerst, wie die Tokens bei ChatGPT aussiehen.\n",
        "Im folgenden Abschnitt kann man beliebige Texte eingeben, um die Zahlung der Tokens zu erfahren.\n",
        "Dadurch können wir vielleicht Gefühl bekommen, wie viel Texte/Sätze wie viel Tokens entsprechen...\n",
        "\n",
        "OpenAI bietet dafür Python-Library, tiktoken, an. Mit Hilfe von tiktoken kann man die Tokenzahlen bei ChatGPT erörtern."
      ],
      "metadata": {
        "id": "sBsEep40HzML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q tiktoken"
      ],
      "metadata": {
        "id": "DPTVy9az45KJ",
        "outputId": "7f70b8a9-779c-4211-a607-8e594fbdd76f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.7 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "encoding = tiktoken.encoding_for_model('gpt-3.5-turbo')\n",
        "text_to_tokens = ''#@param{type:'string'}\n",
        "\n",
        "tokens = encoding.encode(text_to_tokens)\n",
        "print('Zahl der Tokens: ' + str(len(tokens)))\n",
        "print(tokens)\n",
        "\n",
        "\n",
        "for token in tokens:\n",
        "    bytes_token = encoding.decode_single_token_bytes(token)\n",
        "    string_token = bytes_token.decode('utf-8', 'ignore')\n",
        "    print(str(bytes_token) + ' = ' + string_token)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8uowWsey48bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ChatGPT API verwenden"
      ],
      "metadata": {
        "id": "h2rd_mFFI-il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openai"
      ],
      "metadata": {
        "id": "4pbFlEEhjouv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d643e777-6352-464e-d748-4d109e4afe8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hier braucht man den eigenen API-Key. **Der API-Key muss vor fremden Leuten geschützt sein!!**"
      ],
      "metadata": {
        "id": "zmsEphhTEmbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "\n",
        "my_api_key = ''#@param{type:'string'}\n",
        "openai.api_key = my_api_key\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5oNWXnZPjwKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Einstellung des ChatBot: https://platform.openai.com/docs/guides/chat/introduction\n",
        "\n",
        "Die Beschreibung für das Parameter \"temperature\" ist hier zu finden: https://platform.openai.com/docs/api-reference/chat/create#chat/create-temperature\n",
        "\n",
        "temperature kann einen Wert zwischen 0 und 2 nehmen. Der tiefe Wert bedeutet, dass die Antwort der KI akurrat wird. Der hohe Wert von temperature führt zur freien/kreativen Antwort.\n",
        "\n",
        "Um das Gespräch zu beenden, tippe \"Gespräch beenden\" in Prompt"
      ],
      "metadata": {
        "id": "R3ebs6QlJt-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = []\n",
        "system_msg = 'Du bist ein freundlicher KI-ChatBot.\\\n",
        "    Dein Name ist Robita.'\n",
        "messages.append({'role': 'system', 'content': system_msg})\n",
        "print('Sag etwas zu Robita')\n",
        "while True:\n",
        "    message = input ('🙋 Human: ')\n",
        "\n",
        "    messages.append ({'role': 'user', 'content': message})\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model='gpt-3.5-turbo',\n",
        "        messages=messages,\n",
        "        temperature=0.8,\n",
        "    )\n",
        "    reply = response['choices'][0]['message']['content']\n",
        "    messages.append({'role': 'assistant', 'content': reply})\n",
        "    print('---\\n🤖 Robita: ' + reply + '\\n---')\n",
        "\n",
        "    if message == 'Gespräch beenden':\n",
        "        break\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ni5BRgVskYTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gTTS"
      ],
      "metadata": {
        "id": "pzT-tXNhhX1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "from IPython.display import display\n",
        "from io import BytesIO\n",
        "from tempfile import TemporaryFile\n",
        "\n",
        "\n",
        "\n",
        "tts = gTTS('hallo, mein name ist totoro. Heute ist sonnig. Was kann ich für dich tun?', lang='de')\n",
        "f = TemporaryFile()\n",
        "tts.write_to_fp(f)\n",
        "f.seek(0)\n",
        "aud = Audio(f.read(), autoplay=True)\n",
        "display(aud)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "JCXn0xOAhcur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "from IPython.display import display\n",
        "from io import BytesIO\n",
        "from tempfile import TemporaryFile\n",
        "\n",
        "import openai\n",
        "\n",
        "\n",
        "def speech(txt):\n",
        "\n",
        "    tts = gTTS(txt, lang='de')\n",
        "    f = TemporaryFile()\n",
        "    tts.write_to_fp(f)\n",
        "    f.seek(0)\n",
        "    aud = Audio(f.read(), autoplay=True)\n",
        "    display(aud)\n",
        "    f.close()\n",
        "\n",
        "\n",
        "my_api_key = ''#@param{type:'string'}\n",
        "openai.api_key = my_api_key\n",
        "\n",
        "messages = []\n",
        "system_msg = 'Du bist ein freundlicher KI-ChatBot.\\\n",
        "    Dein Name ist Robita.'\n",
        "messages.append({'role': 'system', 'content': system_msg})\n",
        "first_message = 'Sag etwas zu Robita'\n",
        "print(first_message)\n",
        "speech(first_message)\n",
        "\n",
        "while True:\n",
        "    message = input ('🙋 Human: ')\n",
        "\n",
        "    messages.append ({'role': 'user', 'content': message})\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model='gpt-3.5-turbo',\n",
        "        messages=messages,\n",
        "        temperature=0.8,\n",
        "    )\n",
        "    reply = response['choices'][0]['message']['content']\n",
        "    messages.append({'role': 'assistant', 'content': reply})\n",
        "    print('---\\n🤖 Robita: ' + reply + '\\n---')\n",
        "    speech(reply)\n",
        "    if message == 'Gespräch beenden':\n",
        "        break\n",
        "\n"
      ],
      "metadata": {
        "id": "Uh4IR5P5rhnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gespräch mit ChatGPT\n",
        "\n",
        "OpenAI bietet \"Whisper API\", API für Speech-to-Text, an. Mit dieser API probieren wir ein \"Gespräch\" mit ChatGPT."
      ],
      "metadata": {
        "id": "i-eS5w9NkKvF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gTTS openai gradio numpy scipy"
      ],
      "metadata": {
        "id": "1MaH0oklEguO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "my_api_key = ''#@param{type:'string'}\n",
        "openai.api_key = my_api_key"
      ],
      "metadata": {
        "id": "sGgRXKHLmjU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gtts import gTTS\n",
        "from IPython.display import Audio\n",
        "from IPython.display import display\n",
        "from io import BytesIO\n",
        "from tempfile import TemporaryFile\n",
        "import time\n",
        "\n",
        "import openai\n",
        "import gradio as gr\n",
        "\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write\n",
        "\n",
        "\n",
        "\n",
        "def speech(txt):\n",
        "\n",
        "    tts = gTTS(txt, lang='de')\n",
        "    f = TemporaryFile()\n",
        "    tts.write_to_fp(f)\n",
        "    f.seek(0)\n",
        "    aud = Audio(f.read(), autoplay=True)\n",
        "    display(aud)\n",
        "    f.close()\n",
        "\n",
        "def speech_to_text(audio):\n",
        "\n",
        "    # Gradio.Audio gibt die Aufnahme durch Microphon als numpy.Array\n",
        "    # Für whisper muss diese numpy.Array-Daten in ein passendes Format umgewandelt werden\n",
        "    rate, audio_data = audio\n",
        "    scaled = np.int16(audio_data / np.max(np.abs(audio_data)) * 32767)\n",
        "    write('test.wav', rate, scaled)\n",
        "    audio_file = open('test.wav', 'rb')\n",
        "    transcript = openai.Audio.transcribe('whisper-1', audio_file)\n",
        "\n",
        "    return transcript.text\n",
        "\n",
        "\n",
        "def audio_chat(audio, messages_stats):\n",
        "\n",
        "\n",
        "    speech_text = speech_to_text(audio)\n",
        "    message = '🙋 Human: ' + speech_text\n",
        "\n",
        "    messages_stats.append ({'role': 'user', 'content': speech_text})\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model='gpt-3.5-turbo',\n",
        "        messages=messages_stats,\n",
        "        temperature=0.8,\n",
        "    )\n",
        "    reply = response['choices'][0]['message']['content']\n",
        "\n",
        "    speech(reply)\n",
        "    messages_stats.append({'role': 'assistant', 'content': reply})\n",
        "    message += '\\n🤖 Robita: ' + reply + '\\n---'\n",
        "\n",
        "\n",
        "    return message, messages_stats\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    messages = []\n",
        "    system_msg = 'Du bist ein freundlicher KI-ChatBot. Dein Name ist Robita.'\n",
        "    messages.append({'role': 'system', 'content': system_msg})\n",
        "    messages_stats = gr.State(value=messages)\n",
        "    first_message = 'Sag etwas zu Robita'\n",
        "    speech(first_message)\n",
        "\n",
        "\n",
        "    gr.Interface(\n",
        "        title = 'Chatten mit ChatGPT',\n",
        "        fn=audio_chat,\n",
        "\n",
        "        inputs=[\n",
        "            gr.Audio(source='microphone'),\n",
        "            messages_stats\n",
        "        ],\n",
        "        outputs=[\n",
        "            'textbox',\n",
        "            messages_stats\n",
        "        ],\n",
        "        live=True\n",
        "    ).launch()"
      ],
      "metadata": {
        "id": "TcPZI3aNG-k_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Referenz\n",
        "\n",
        "Dokumentation für Chat Completions (ChatGPT)\n",
        "https://platform.openai.com/docs/guides/chat/chat-completions-beta\n",
        "\n"
      ],
      "metadata": {
        "id": "xTYCpvmaGC5d"
      }
    }
  ]
}